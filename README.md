# LLM Interview Questions
This repository contains LLM (Large language model) interview question asked in top companies like Google, Nvidia , Meta , Microsoft &amp; fortune 500 companies.

# 100+ Interview Questions for Large Language Models (LLM)

Explore 100+ interview questions for mastering Large Language Models, curated with insights from real-world scenarios and industry-leading companies like FAANG and Fortune 500. This guide is organized into 14 categories to facilitate learning and preparation.

---

## Table of Contents

1. [Prompt Engineering & Basics of LLM](#prompt-engineering--basics-of-llm)
2. [Retrieval Augmented Generation (RAG)](#retrieval-augmented-generation-rag)
3. [Chunking Strategies](#chunking-strategies)
4. [Embedding Models](#embedding-models)
5. [Internal Working of Vector Databases](#internal-working-of-vector-databases)
6. [Advanced Search Algorithms](#advanced-search-algorithms)
7. [Language Models Internal Working](#language-models-internal-working)
8. [Supervised Fine-Tuning of LLM](#supervised-fine-tuning-of-llm)
9. [Preference Alignment (RLHF/DPO)](#preference-alignment-rlhfdpo)
10. [Evaluation of LLM System](#evaluation-of-llm-system)
11. [Hallucination Control Techniques](#hallucination-control-techniques)
12. [Deployment of LLM](#deployment-of-llm)
13. [Agent-Based System](#agent-based-system)
14. [Prompt Hacking](#prompt-hacking)
15. [Case Study & Scenario-Based Questions](#case-study--scenario-based-questions)

---

## Prompt Engineering & Basics of LLM

- **What is the difference between Predictive/Discriminative AI and Generative AI?**
- **What is LLM, and how are LLMs trained?**
- **What is a token in the language model?**
- **How to estimate the cost of running SaaS-based and Open Source LLM models?**
- **Explain the Temperature parameter and how to set it.**
- **What are different decoding strategies for picking output tokens?**
- **How to use stop sequences in LLMs?**
- **Explain the basic structure and types of prompt engineering.**
- **What is hallucination, and how can it be controlled using prompt engineering?**
- **How to improve the reasoning ability of LLM through prompt engineering?**

[Back to Top](#table-of-contents)

---

## Retrieval Augmented Generation (RAG)

- **How does RAG work?**
- **What are some benefits of using the RAG system?**
- **When should I use Fine-tuning instead of RAG?**
- **What are the architecture patterns for customizing LLM with proprietary data?**

[Back to Top](#table-of-contents)

---

## Chunking Strategies

- **What is chunking, and why do we chunk our data?**
- **What factors influence chunk size?**
- **What are the different types of chunking methods?**
- **How to find the ideal chunk size?**

[Back to Top](#table-of-contents)

---

## Embedding Models

- **What are vector embeddings, and what is an embedding model?**
- **How is an embedding model used in the context of LLM applications?**
- **What is the difference between embedding short and long content?**
- **How to benchmark embedding models on your data?**

[Back to Top](#table-of-contents)

---

## Internal Working of Vector Databases

- **What is a vector database?**
- **How does a vector database differ from traditional databases?**
- **Explain vector search strategies like clustering and Locality-Sensitive Hashing.**
- **How to decide the best vector database for your needs?**

[Back to Top](#table-of-contents)

---

## Advanced Search Algorithms

- **What are architecture patterns for information retrieval & semantic search?**
- **How can you achieve efficient and accurate search results in large-scale datasets?**
- **Explain keyword-based retrieval and re-ranking models.**

[Back to Top](#table-of-contents)

---

## Language Models Internal Working

- **Detailed explanation of Transformer architecture and self-attention.**
- **Advantages of using a transformer over LSTM.**
- **How to increase the context length of an LLM?**
- **What is a mixture of expert models?**

[Back to Top](#table-of-contents)

---

## Supervised Fine-Tuning of LLM

- **What is fine-tuning, and why is it needed?**
- **How to create fine-tuning datasets for Q&A?**
- **What are different re-parameterized methods for fine-tuning?**
- **What is catastrophic forgetting in LLMs?**

[Back to Top](#table-of-contents)

---

## Preference Alignment (RLHF/DPO)

- **What is RLHF, and how is it used?**
- **Explain different preference alignment methods.**
- **What is the reward hacking issue in RLHF?**

[Back to Top](#table-of-contents)

---

## Evaluation of LLM System

- **How to evaluate RAG-based systems?**
- **What are different metrics for evaluating LLMs?**

[Back to Top](#table-of-contents)

---

## Hallucination Control Techniques

- **What are different forms of hallucinations?**
- **How to control hallucinations at various levels?**

[Back to Top](#table-of-contents)

---

## Deployment of LLM

- **Why does quantization not decrease the accuracy of LLM?**

[Back to Top](#table-of-contents)

---

## Agent-Based System

- **What are agents, and why are they needed?**
- **Explain ReAct prompting with examples.**
- **Difference between OpenAI functions and LangChain agents.**

[Back to Top](#table-of-contents)

---

## Prompt Hacking

- **What is prompt hacking, and why is it important?**
- **What are the different defense tactics against prompt hacking?**

[Back to Top](#table-of-contents)

---

## Case Study & Scenario-Based Questions

- **How to optimize the cost of an overall LLM system?**

[Back to Top](#table-of-contents)

---

*For more resources, visit [Mastering LLM](https://www.masteringllm.com).*
